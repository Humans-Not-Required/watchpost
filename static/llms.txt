# Watchpost â€” Agent-Native Monitoring Service
# API Base: /api/v1

## Quick Start
POST /api/v1/monitors â€” Create a monitor (returns manage_key)
GET /api/v1/monitors/:id â€” View monitor status
GET /api/v1/monitors/:id/heartbeats â€” Check history
GET /api/v1/monitors/:id/uptime â€” Uptime stats (24h/7d/30d/90d)
GET /api/v1/monitors/:id/incidents â€” Incident history
GET /api/v1/status â€” Public status page
GET /api/v1/dashboard â€” Aggregate dashboard stats (totals, uptime averages). With admin key: includes recent incidents, slowest monitors. Without auth: aggregate stats only (no individual monitor data).
GET /api/v1/admin/verify â€” Verify admin key validity. Returns {"valid": true/false}. Accepts key via Bearer header, X-API-Key header, or ?key= query param.
GET /api/v1/uptime-history?days=30 â€” Daily uptime percentages over time (aggregate across all monitors, max 90 days)
GET /api/v1/monitors/:id/uptime-history?days=30 â€” Daily uptime percentages for a specific monitor

## Auth
- Create monitor: no auth (returns manage_key, save it!)
- Read: no auth (use monitor UUID)
- Write: manage_key via Bearer header, X-API-Key, or ?key= param

## Monitor Types
- http (default) â€” HTTP/HTTPS endpoint monitoring (GET, HEAD, POST)
- tcp â€” TCP port connectivity check (connect to host:port)
- dns â€” DNS record resolution check (verify hostname resolves correctly)

Set monitor_type on create: {"monitor_type": "tcp", "url": "db.example.com:5432", "name": "Database"}
DNS example: {"monitor_type": "dns", "url": "example.com", "dns_record_type": "A", "dns_expected": "93.184.216.34"}
Default monitor_type is "http" if omitted.

## DNS Monitors
- url: hostname to resolve (e.g., "example.com" or "dns://example.com")
- dns_record_type: A (default), AAAA, CNAME, MX, TXT, NS, SOA, PTR, SRV, CAA
- dns_expected: optional â€” if set, resolved value must match (case-insensitive, trailing dot ignored)
- If dns_expected is omitted, check passes as long as resolution succeeds (any value returned)
- Response time = DNS resolution latency
- Status: up (resolved, matches expected), down (no records, mismatch, timeout), degraded (slow resolution)

## Validation
- HTTP monitors: URL must start with http:// or https://
- TCP monitors: URL must be host:port format (e.g., "example.com:443" or "tcp://example.com:443")
- DNS monitors: URL must be a valid hostname (no http:// scheme, spaces not allowed)
- Headers must be a JSON object (not array or string)
- interval_seconds: min 600 (10 minutes), default 600
- timeout_ms: min 1000, max 60000, default 10000
- confirmation_threshold: min 1, max 10, default 2
- response_time_threshold_ms: min 100 (if set)

## Monitor Methods (HTTP only)
GET, HEAD, POST
(TCP and DNS monitors ignore the method field)

## Redirect Handling
By default, monitors follow HTTP redirects (301, 302, etc.) up to 10 hops.
Set follow_redirects: false on create/update to disable redirect following (useful for monitoring that a redirect is in place).
When follow_redirects is true (default), the final response after all redirects is evaluated against expected_status.

## Check Statuses
up, down, degraded (response time exceeds threshold), unknown (never checked)

## Response Time Alerts
Set response_time_threshold_ms on a monitor to get degraded status when response time exceeds threshold.
Triggers monitor.degraded / monitor.recovered webhook events.
Set to null to disable. Minimum: 100ms.

## Notification Types
webhook (POST JSON to URL), email (SMTP)

### Webhook Notifications
POST /api/v1/monitors/:id/notifications with {"name": "Slack", "channel_type": "webhook", "config": {"url": "https://hooks.slack.com/..."}}
On incident, POSTs JSON with event, monitor info, and incident details to the URL.
Delivery includes automatic retry: up to 3 attempts with exponential backoff (2s, 4s delays between retries).
Every delivery attempt is logged for audit via GET /api/v1/monitors/:id/webhook-deliveries.

#### Chat Payload Format
Set "payload_format": "chat" in config to send simple text messages instead of structured JSON:
  config: {"url": "https://chat.example.com/api/v1/hook/token", "payload_format": "chat"}
Delivers: {"content": "ðŸ”´ **Blog** â€” DOWN\nCause: Connection refused", "sender": "Watchpost"}
Compatible with Local Agent Chat incoming webhooks, Slack, and other chat systems that accept {"content": "..."} payloads.
Default (no payload_format or "json") sends the full structured WebhookPayload as before.

### Webhook Delivery Log
GET /api/v1/monitors/:id/webhook-deliveries â€” list delivery attempts (manage key required)
  ?limit=N (1-200, default 50), ?after=<seq> cursor, ?event=incident.created, ?status=failed
  Returns: {deliveries: [{id, delivery_group, event, url, attempt, status, status_code, error_message, response_time_ms, created_at, seq}], total: N}
  delivery_group groups all retry attempts for one notification dispatch.
  status values: success, failed.
  Retry policy: 3 attempts max, 2s then 4s backoff. Logged per attempt.

### Email Notifications
POST /api/v1/monitors/:id/notifications with {"name": "Ops Email", "channel_type": "email", "config": {"address": "ops@example.com"}}
Sends formatted email (HTML + plain text) on incident creation, resolution, degraded, and maintenance events.
Requires SMTP server configuration via environment variables:
  SMTP_HOST â€” SMTP server hostname (required to enable email)
  SMTP_PORT â€” Port (default: 587)
  SMTP_USERNAME â€” Auth username
  SMTP_PASSWORD â€” Auth password
  SMTP_FROM â€” Sender address (default: watchpost@<SMTP_HOST>)
  SMTP_TLS â€” "starttls" (default), "tls", or "none"

## SSE Event Streams (real-time)
GET /api/v1/events â€” global event stream (all monitors)
GET /api/v1/monitors/:id/events â€” per-monitor event stream

Event types: check.completed, incident.created, incident.resolved

## Monitor Groups
POST /api/v1/monitors with "group_name": "Infrastructure" â€” assign monitors to a group on creation
PATCH /api/v1/monitors/:id with "group_name": "APIs" â€” change group (empty string removes)
GET /api/v1/groups â€” list all unique groups across public monitors
GET /api/v1/monitors?group=Infrastructure â€” filter monitors by group
GET /api/v1/status?group=Infrastructure â€” filter status page by group
Groups organize monitors into sections on the status page. Grouped monitors are sorted by group name, then by name.

## Tags
POST /api/v1/monitors with "tags": ["api", "prod"] â€” tag monitors on creation
PATCH /api/v1/monitors/:id with "tags": ["api", "staging"] â€” update tags
GET /api/v1/tags â€” list all unique tags across public monitors
GET /api/v1/monitors?tag=prod â€” filter monitors by tag
GET /api/v1/status?tag=prod â€” filter status page by tag

## Search & Filter
GET /api/v1/monitors?search=keyword â€” filter by name/URL
GET /api/v1/monitors?status=up â€” filter by status (up/down/degraded/unknown)
GET /api/v1/status?search=keyword&status=down&group=Infrastructure â€” combined filters
GET /api/v1/status?ids=id1,id2,id3 â€” batch status check: filter to specific monitors by ID. Returns only public monitors matching the given IDs. Non-existent and private IDs are silently excluded. Useful for agents that need to check multiple specific monitors without N round trips.

## Bulk Operations
POST /api/v1/monitors/bulk â€” create up to 50 monitors at once
  Body: {"monitors": [{"name": "...", "url": "..."}, ...]}
  Returns: {"created": [...], "errors": [...], "total": N, "succeeded": N, "failed": N}
  Each created monitor includes its manage_key (save them!)
  Partial success: some monitors may fail while others succeed

## Export
GET /api/v1/monitors/:id/export â€” export monitor config (auth required)
  Returns monitor settings in a format you can re-import via POST /monitors or /monitors/bulk
  Useful for backup, migration, or cloning monitors

## Endpoints
POST /api/v1/monitors â€” create monitor
POST /api/v1/monitors/bulk â€” bulk create monitors (up to 50)
GET /api/v1/monitors/:id/export â€” export monitor config (auth)
GET /api/v1/monitors â€” list public monitors (supports ?search= and ?status= filters)
GET /api/v1/monitors/:id â€” get monitor
PATCH /api/v1/monitors/:id â€” update (auth)
DELETE /api/v1/monitors/:id â€” delete (auth)
POST /api/v1/monitors/:id/pause â€” pause checks (auth)
POST /api/v1/monitors/:id/resume â€” resume checks (auth)
GET /api/v1/monitors/:id/heartbeats â€” check history
GET /api/v1/monitors/:id/uptime â€” uptime stats
GET /api/v1/monitors/:id/uptime-history â€” daily uptime history (?days=N, max 90)
GET /api/v1/uptime-history â€” aggregate daily uptime history (?days=N, max 90)
GET /api/v1/monitors/:id/incidents â€” incidents
GET /api/v1/incidents/:id â€” single incident detail (includes notes_count)
POST /api/v1/incidents/:id/acknowledge â€” ack incident (auth)
POST /api/v1/incidents/:id/notes â€” add investigation note (auth)
GET /api/v1/incidents/:id/notes â€” list notes (chronological, no auth)
POST /api/v1/monitors/:id/notifications â€” add notification (auth)
GET /api/v1/monitors/:id/notifications â€” list notifications (auth)
DELETE /api/v1/notifications/:id â€” remove notification (auth)
PATCH /api/v1/notifications/:id â€” enable/disable notification (auth)
POST /api/v1/monitors/:id/maintenance â€” create maintenance window (auth)
GET /api/v1/monitors/:id/maintenance â€” list maintenance windows
DELETE /api/v1/maintenance/:id â€” delete maintenance window (auth)
GET /api/v1/tags â€” list all unique tags (public monitors)
GET /api/v1/groups â€” list all unique groups (public monitors)
GET /api/v1/monitors/:id/sla â€” SLA status with error budget
GET /api/v1/monitors/:id/badge/uptime â€” SVG uptime badge (?period=24h|7d|30d|90d, ?label=)
GET /api/v1/monitors/:id/badge/status â€” SVG status badge (?label=)
GET /api/v1/events â€” global SSE event stream
GET /api/v1/monitors/:id/events â€” per-monitor SSE event stream
GET /api/v1/settings â€” get status page branding (title, description, logo_url)
PUT /api/v1/settings â€” update branding (admin key required)
GET /api/v1/status â€” public status page (supports ?tag= filter, includes branding)
GET /api/v1/health â€” service health
POST /api/v1/locations â€” register check location (admin key required, returns probe_key)
GET /api/v1/locations â€” list check locations
GET /api/v1/locations/:id â€” get check location
DELETE /api/v1/locations/:id â€” remove check location (admin key required)
POST /api/v1/probe â€” submit probe results from remote location (probe_key auth)
GET /api/v1/monitors/:id/locations â€” per-location status for a monitor
GET /api/v1/monitors/:id/consensus â€” multi-region consensus status
PUT /api/v1/monitors/:id/alert-rules â€” set alert rules (auth)
GET /api/v1/monitors/:id/alert-rules â€” get alert rules (auth)
DELETE /api/v1/monitors/:id/alert-rules â€” remove alert rules (auth)
GET /api/v1/monitors/:id/alert-log â€” alert notification log (auth, ?limit= ?after=)
GET /api/v1/monitors/:id/webhook-deliveries â€” webhook delivery audit log (auth, ?limit= ?after= ?event= ?status=)
POST /api/v1/monitors/:id/dependencies â€” add dependency (auth)
GET /api/v1/monitors/:id/dependencies â€” list dependencies (no auth)
DELETE /api/v1/monitors/:id/dependencies/:dep_id â€” remove dependency (auth)
GET /api/v1/monitors/:id/dependents â€” list monitors that depend on this one (no auth)

## Status Page Branding
GET /api/v1/settings â€” returns current branding: {"title": "...", "description": "...", "logo_url": "..."}
PUT /api/v1/settings â€” update branding fields (admin key via Bearer header). Send only fields to change; empty string clears a field.
  Body: {"title": "My Status Page", "description": "Service availability dashboard", "logo_url": "https://..."}
  Auth: admin key (auto-generated on first run, printed to stdout)
Branding is also included in GET /api/v1/status response as a "branding" field (omitted when no branding is set).

## Status Badges (SVG)
GET /api/v1/monitors/:id/badge/uptime â€” SVG uptime badge (shields.io style)
  ?period=24h|7d|30d|90d (default: 24h)
  ?label=custom+label (default: "uptime 24h")
  Returns image/svg+xml â€” embed in README: ![uptime](https://watch.example.com/api/v1/monitors/:id/badge/uptime?period=7d)
GET /api/v1/monitors/:id/badge/status â€” SVG current status badge
  ?label=custom+label (default: "status")
  Color-coded: green=up, yellow=degraded, grey=paused/maintenance/unknown, red=down

## SLA Tracking
Set an uptime target on any monitor to track SLA compliance with error budgets.
POST /api/v1/monitors with "sla_target": 99.9 â€” set 99.9% uptime target (optional: "sla_period_days": 30)
PATCH /api/v1/monitors/:id with "sla_target": 99.95 â€” update target. Set to null to remove.
GET /api/v1/monitors/:id/sla â€” SLA status with error budget tracking
  Returns: target_pct, period_days, current_pct, total_checks, successful_checks,
           downtime_estimate_seconds, budget_total_seconds, budget_remaining_seconds,
           budget_used_pct, status (met|at_risk|breached), period_start, period_end
  - "met": uptime meets target and >25% of error budget remains
  - "at_risk": uptime meets target but <25% of error budget remains
  - "breached": current uptime is below the target
  - "degraded" heartbeats count as successful (service responded, just slow)
  sla_target: 0-100 (percentage), sla_period_days: 1-365 (default: 30)
  Returns 404 with code SLA_NOT_CONFIGURED if no target is set on the monitor.

## Incident Notes (Investigation Timeline)
Track investigation progress with structured notes on incidents.
POST /api/v1/incidents/:id/notes â€” add a note (auth required)
  Body: {"content": "Investigating DNS resolution failure", "author": "Nanook"}
  Author defaults to "anonymous" if omitted. Content: 1-10,000 chars. Author: 1-200 chars.
GET /api/v1/incidents/:id/notes â€” list notes chronologically (no auth, ?limit= up to 200)
GET /api/v1/incidents/:id â€” single incident detail with notes_count field
Notes are CASCADE deleted when the parent incident or monitor is removed.

## Alert Rules (Repeat & Escalation)
Configure repeat notifications and escalation policies per monitor.
PUT /api/v1/monitors/:id/alert-rules â€” set alert rules (auth required, upsert)
  Body: {"repeat_interval_minutes": 15, "max_repeats": 10, "escalation_after_minutes": 30}
  - repeat_interval_minutes: re-send notifications every N minutes while incident is open. 0 = disabled. Min 5.
  - max_repeats: cap on repeat notifications per incident. Default 10, max 100.
  - escalation_after_minutes: send escalation alert if incident not acknowledged within N minutes. 0 = disabled. Min 5.
GET /api/v1/monitors/:id/alert-rules â€” get current alert rules (auth required). Returns 404 if no rules configured.
DELETE /api/v1/monitors/:id/alert-rules â€” remove alert rules (auth required).
GET /api/v1/monitors/:id/alert-log â€” view notification history (auth required, ?limit=N, ?after=timestamp).
  Returns: [{id, monitor_id, incident_id, channel_id, alert_type, event, sent_at}]
  alert_type values: initial, reminder, escalation, resolved.

## Maintenance Windows
Schedule downtime so checks still run but incidents are suppressed.
POST /api/v1/monitors/:id/maintenance with {"title": "Deploy v2", "starts_at": "2026-02-10T14:00:00Z", "ends_at": "2026-02-10T15:00:00Z"}
During an active window, monitor status shows "maintenance" instead of "down".
Heartbeats are still recorded. No incidents created. SSE events: maintenance.started, maintenance.ended.

## Multi-Region Check Locations
Register remote check locations to submit probe results from multiple geographic regions.
This enables distributed monitoring: agents in different regions report back their check results,
giving you a multi-perspective view of service health.

### Managing Check Locations (admin key required)
POST /api/v1/locations â€” Register a check location (returns probe_key)
  Body: {"name": "US East", "region": "us-east-1"}
  The probe_key is shown once â€” save it! Remote probes authenticate with it.
GET /api/v1/locations â€” List all check locations (no auth). Each includes health_status field.
GET /api/v1/locations/:id â€” Get a specific check location (no auth). Includes health_status.
DELETE /api/v1/locations/:id â€” Remove a check location (admin key required)

### Probe Health Tracking
Locations include a `health_status` field computed from their reporting status:
  - "healthy" â€” active and reported recently (within PROBE_STALE_MINUTES, default 30)
  - "new" â€” active but has never submitted a probe result
  - "stale" â€” active but hasn't reported within the threshold
  - "disabled" â€” manually disabled or auto-disabled due to staleness
Stale locations are auto-disabled every 5 minutes by the checker loop.
Configure threshold: PROBE_STALE_MINUTES env var (default: 30 minutes).

### Submitting Probe Results (probe_key auth)
POST /api/v1/probe â€” Submit check results from a remote location
  Auth: probe_key via Bearer header, X-API-Key, or ?key= param
  Body: {"results": [{"monitor_id": "...", "status": "up|down|degraded", "response_time_ms": 123, "status_code": 200, "error_message": null, "checked_at": "2026-02-15T12:00:00"}]}
  Max 100 results per submission. Each result is validated independently (partial success possible).
  Response: {"accepted": N, "rejected": N, "errors": [...]}

### Per-Location Status
GET /api/v1/monitors/:id/locations â€” Per-location status for a monitor
  Returns the latest probe result from each active check location for the given monitor.
  Response: [{"location_id": "...", "location_name": "US East", "region": "us-east-1", "last_status": "up", "last_response_time_ms": 50, "last_checked_at": "..."}]

### Multi-Region Consensus
When a monitor has `consensus_threshold` set, status is determined by aggregating results across all check locations.
The monitor is marked "down" only when at least `consensus_threshold` locations report down.
This prevents false positives from a single location experiencing issues.

POST /api/v1/monitors with "consensus_threshold": 2 â€” require 2+ locations to agree on "down"
PATCH /api/v1/monitors/:id with "consensus_threshold": 3 â€” update threshold. Set to null to disable consensus.
GET /api/v1/monitors/:id/consensus â€” current consensus status
  Returns: consensus_threshold, total_locations, up_count, down_count, degraded_count,
           unknown_count, effective_status, and per-location details.
  Returns 400 with code CONSENSUS_NOT_CONFIGURED if no threshold is set.

Consensus logic:
- If down_count >= threshold â†’ monitor is "down" (incident created)
- If (down_count + degraded_count) >= threshold â†’ "degraded"
- Otherwise â†’ "up"
- Evaluated automatically after every local check and every probe submission.
- When consensus is active, the local checker writes heartbeats but defers incident lifecycle to the consensus evaluator.

### Heartbeat Location Tracking
Heartbeats from remote probes include a location_id field linking to the check location.
Local checker heartbeats have location_id: null.
GET /api/v1/monitors/:id/heartbeats â€” heartbeats include location_id when present.

## Monitor Dependencies (Alert Suppression)
Define upstream dependencies between monitors. When an upstream monitor is down,
downstream monitor alerts are suppressed to prevent alert storms.

POST /api/v1/monitors/:id/dependencies â€” Add dependency (auth required)
  Body: {"depends_on_id": "<upstream_monitor_id>"}
  Validates: no self-dependency, no circular chains, both monitors exist.
  Returns 201 with dependency details including upstream name and status.
GET /api/v1/monitors/:id/dependencies â€” List dependencies (no auth)
  Returns: [{id, monitor_id, depends_on_id, depends_on_name, depends_on_status, created_at}]
DELETE /api/v1/monitors/:id/dependencies/:dep_id â€” Remove dependency (auth required)
GET /api/v1/monitors/:id/dependents â€” Reverse lookup: who depends on me? (no auth)

### How Suppression Works
- When a monitor goes down, the checker checks all its dependencies
- If any dependency is currently "down", incident creation is suppressed
- Heartbeats are still recorded honestly (status reflects reality)
- When the dependency recovers, the next check creates the incident if still down
- Circular dependencies are prevented at creation time (graph walk)
- CASCADE delete: deleting either monitor removes the dependency

### Example Topology
  Database â†’ API â†’ Web App
  If Database goes down: API and Web App get "down" heartbeats but no incidents.
  When Database recovers: API and Web App get incidents if still failing.

## Status Pages

Named collections of monitors with their own branding, slug, and optional custom domain.
Useful for organizing monitors into logical groups (e.g., "Production", "Staging", "Internal") with separate public-facing status pages.

### CRUD
POST /api/v1/status-pages â€” Create a new status page. Returns manage_key.
  Required: slug (URL-safe identifier, a-z0-9_-), title
  Optional: description, logo_url, custom_domain, is_public (default true)
GET /api/v1/status-pages â€” List all public status pages
GET /api/v1/status-pages/:slug_or_id â€” Get status page detail with monitors and overall status
PATCH /api/v1/status-pages/:slug_or_id â€” Update (manage_key required). Can change slug, title, description, logo_url, custom_domain, is_public.
DELETE /api/v1/status-pages/:slug_or_id â€” Delete (manage_key required). Monitors are not deleted.

### Monitor Assignment
POST /api/v1/status-pages/:slug_or_id/monitors â€” Add monitors (manage_key required)
  Body: {"monitor_ids": ["id1", "id2", ...]} â€” up to 100 at once
  Duplicate assignments are silently skipped.
DELETE /api/v1/status-pages/:slug_or_id/monitors/:monitor_id â€” Remove monitor (manage_key required)
GET /api/v1/status-pages/:slug_or_id/monitors â€” List monitors on a page (public)

### How It Works
- Each status page has its own manage_key (same pattern as monitors)
- Pages can be accessed by slug or ID
- Non-public pages are unlisted but still accessible by slug (like unlisted YouTube videos)
- Deleting a status page removes assignments but not the monitors themselves
- Deleting a monitor removes it from all status pages (CASCADE)
- The detail endpoint returns monitor status data (uptime, response time, incidents) same as the global status page


## Skills Discovery
GET /.well-known/skills/index.json â€” Skills discovery index (Cloudflare RFC). Lists available skills for progressive loading by compatible agents.
GET /.well-known/skills/watchpost/SKILL.md â€” Integration skill with YAML frontmatter (agentskills.io format). Contains quick start, patterns, auth model, rate limits, and gotchas. Compatible with Claude Code, OpenAI Codex, VS Code Copilot, and other skills-compatible agents.
